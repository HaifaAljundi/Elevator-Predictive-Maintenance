{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "60700828",
      "metadata": {
        "id": "60700828"
      },
      "source": [
        "<center> <span style=\"color:#0F3460;font-size:30px; font-weight: bold; padding:250px ;\">Elevator Predictive Maintenance</span> </center>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2309e998",
      "metadata": {
        "id": "2309e998"
      },
      "source": [
        "<span> <center>Datasets:https://www.kaggle.com/datasets/shivamb/elevator-predictive-maintenance-dataset </center></span>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbff3fae",
      "metadata": {
        "id": "cbff3fae"
      },
      "source": [
        "<center><span style=\"color:#0F3460;font-size:21px; font-weight: bold;\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0a9c07f",
      "metadata": {
        "id": "e0a9c07f"
      },
      "source": [
        "<span style=\"color:#0F3460;font-size:21px; font-weight: bold;\">1.1 Importing libaries </span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b007f790",
      "metadata": {
        "id": "b007f790"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9c5f444",
      "metadata": {
        "id": "c9c5f444"
      },
      "source": [
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "474bf4e9",
      "metadata": {
        "id": "474bf4e9"
      },
      "source": [
        "  <center><span style=\"color:#0F3460;font-size:30px; font-weight: bold;\">Part 1</span> </center> <br>\n",
        "  \n",
        "  <center><span style=\"color:#0F3460;font-size:23px; font-weight: bold;\">Data Preprocessing</span>  </center>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c2191c2",
      "metadata": {
        "id": "2c2191c2"
      },
      "source": [
        " <span style=\"color:#0F3460;font-size:19px; font-weight: bold;\">1.2 Importing My Data From *csv* File</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "yzsUfV7jvXOE",
      "metadata": {
        "id": "yzsUfV7jvXOE"
      },
      "outputs": [],
      "source": [
        "epm = pd.read_csv(\"predictive-maintenance-dataset.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b21f6f95",
      "metadata": {
        "id": "b21f6f95"
      },
      "source": [
        " <span style=\"color:#0F3460;font-size:19px; font-weight: bold;\">1.3 Top 5 Rows</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a735a4e4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "a735a4e4",
        "outputId": "a47e2140-5b1a-4872-fafb-4914dd68492d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>revolutions</th>\n",
              "      <th>humidity</th>\n",
              "      <th>vibration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>93.744</td>\n",
              "      <td>73.999</td>\n",
              "      <td>18.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>93.740</td>\n",
              "      <td>73.999</td>\n",
              "      <td>18.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>93.736</td>\n",
              "      <td>73.998</td>\n",
              "      <td>18.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>93.732</td>\n",
              "      <td>73.998</td>\n",
              "      <td>18.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>93.729</td>\n",
              "      <td>73.998</td>\n",
              "      <td>18.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID  revolutions  humidity  vibration\n",
              "0   1       93.744    73.999       18.0\n",
              "1   2       93.740    73.999       18.0\n",
              "2   3       93.736    73.998       18.0\n",
              "3   4       93.732    73.998       18.0\n",
              "4   5       93.729    73.998       18.0"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "epm.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "116675cf",
      "metadata": {
        "id": "116675cf"
      },
      "source": [
        "- ID: Used for tracking and managing records.\n",
        "- Revolutions: Key feature for assessing wear and predicting when maintenance is needed based on usage.\n",
        "- Humidity: Helps in understanding environmental factors affecting machinery performance.\n",
        "- Vibration: Critical for early detection of mechanical issues, allowing for preventive actions.\n",
        "- x1 to x5: Enhance the model by providing additional context and potentially capturing complex interactions affecting machinery health.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e732921",
      "metadata": {
        "id": "0e732921"
      },
      "source": [
        " <span style=\"color:#0F3460;font-size:19px; font-weight: bold;\">1.4 Info</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e5edd41",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e5edd41",
        "outputId": "2fa4861c-ad02-47d5-9bb0-566b864eaaad"
      },
      "outputs": [],
      "source": [
        "epm.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "220d70d2",
      "metadata": {
        "id": "220d70d2"
      },
      "source": [
        " <span style=\"color:#0F3460;font-size:19px; font-weight: bold;\">1.5 Cleaning</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4841ae2c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4841ae2c",
        "outputId": "b8d752c6-2da4-4ba7-c049-00ab61ca69e4"
      },
      "outputs": [],
      "source": [
        "epm_clean = epm.isnull().sum()\n",
        "epm_clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "906aba60",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "906aba60",
        "outputId": "e0503a9f-78c6-41c0-e110-db5ac1859c43"
      },
      "outputs": [],
      "source": [
        "epm_clean = epm.dropna()\n",
        "epm_clean.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02230541",
      "metadata": {},
      "source": [
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a5fc8a8",
      "metadata": {
        "id": "6a5fc8a8"
      },
      "source": [
        " <span style=\"color:#0F3460;font-size:19px; font-weight: bold;\">1.6 Statistical Summary </span>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c56e5154",
      "metadata": {},
      "outputs": [],
      "source": [
        "epm_clean.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d00b06e4",
      "metadata": {},
      "outputs": [],
      "source": [
        "revolutions = epm_clean['revolutions']\n",
        "plt.hist(revolutions)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "729ec530",
      "metadata": {},
      "outputs": [],
      "source": [
        "humidity = epm_clean['humidity']\n",
        "plt.hist(humidity)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c515191f",
      "metadata": {},
      "outputs": [],
      "source": [
        "vibration = epm_clean['vibration']\n",
        "plt.hist(vibration)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a9e2071",
      "metadata": {},
      "source": [
        " <span style=\"color:#0F3460;font-size:19px; font-weight: bold;\">1.7 Relationships between Features</span>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2f24d7c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        },
        "id": "b2f24d7c",
        "outputId": "2e4bba52-7ffe-472b-bc73-aa7fcc592d8c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load your dataset\n",
        "# emp = pd.read_csv('path_to_your_dataset.csv')\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "corr = epm_clean.corr()\n",
        "\n",
        "# Create a heatmap\n",
        "plt.figure(figsize=(10, 8))  # Adjusts the size of the plot\n",
        "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='coolwarm', cbar=True, square=True)\n",
        "\n",
        "# Customizing the plot\n",
        "plt.title('Heatmap of Feature Correlations')\n",
        "plt.xticks(rotation=45)  # Rotates the x-axis labels for better readability\n",
        "plt.yticks(rotation=45)  # Rotates the y-axis labels for better readability\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d2a937b",
      "metadata": {},
      "source": [
        "X5 and humidity \n",
        "X4, x3, x2, x1 and revolution \n",
        "\n",
        "Non of the sensors work good with vibration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23530e89",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the training data\n",
        "train_df = pd.read_csv('predictive-maintenance-dataset.csv', delimiter=',', header=0)\n",
        "\n",
        "# Print the shape and first few rows\n",
        "print('Shape of Train dataset: ', train_df.shape)\n",
        "print(train_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da8bb527",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(train_df.columns)  # Print column indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4960888",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(train_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16f27dd1",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Step 3: Print the shape of the DataFrame to understand its dimensions\n",
        "print('Initial shape of Train dataset: ', train_df.shape)\n",
        "\n",
        "# Step 4: Check the actual number of columns\n",
        "num_columns = train_df.shape[1]\n",
        "print(f\"Number of columns: {num_columns}\")\n",
        "\n",
        "# Step 5: Define column names (ensure the count matches the number of columns)\n",
        "col_names = ['ID', 'revolutions', 'humidity', 'vibration']\n",
        "\n",
        "# Ensure the number of column names matches the number of columns in the DataFrame\n",
        "if len(col_names) == num_columns:\n",
        "    # Assign column names\n",
        "    train_df.columns = col_names\n",
        "else:\n",
        "    print(\"Error: The number of column names does not match the number of columns in the DataFrame\")\n",
        "    print(f\"Expected {num_columns} column names but got {len(col_names)}.\")\n",
        "\n",
        "# Print the columns to verify\n",
        "print(\"Columns of the DataFrame:\", train_df.columns)\n",
        "\n",
        "# Print the shape and head of the Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5c57205",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read the test data\n",
        "test_df = pd.read_csv(\"predictive-maintenance-dataset.csv\")\n",
        "\n",
        "# Inspect the test DataFrame\n",
        "print(test_df.shape) \n",
        "print(test_df.head()) \n",
        "print(test_df.columns)  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba07cf3c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Step 1: Read the CSV file with the correct delimiter (comma in this case)\n",
        "truth_df = pd.read_csv('predictive-maintenance-dataset.csv', delimiter=',', header=0)\n",
        "truth_df.drop(truth_df.columns[[1]], axis=1, inplace=True)\n",
        "print(truth_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67df41d7",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df.sort_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f6b54a7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# sort based on id and cycle\n",
        "train_df = train_df.sort_values(['ID','revolutions'])\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a20ffa8d",
      "metadata": {},
      "source": [
        "<span style=\"color:#0F3460;font-size:19px; font-weight: bold;\">Data Preprocessing </span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e204bb10",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "# TRAIN\n",
        "#######\n",
        "# Data Labeling - generate column RUL(Remaining Usefull Life or Time to Failure)\n",
        "rul = pd.DataFrame(train_df.groupby('ID')['revolutions'].max()).reset_index()\n",
        "rul.columns = ['ID', 'max']\n",
        "train_df = train_df.merge(rul, on=['ID'], how='left')\n",
        "train_df['RUL'] = train_df['max'] - train_df['revolutions']\n",
        "train_df.drop('max', axis=1, inplace=True)\n",
        "# generate label columns for training data\n",
        "# we will only make use of \"label1\" for binary classification,\n",
        "# while trying to answer the question: is a specific engine going to fail within w1 revolutionss?\n",
        "w1 = 30\n",
        "w0 = 15\n",
        "train_df['label1'] = np.where(train_df['RUL'] <= w1, 1, 0 )\n",
        "train_df['label2'] = train_df['label1']\n",
        "train_df.loc[train_df['RUL'] <= w0, 'label2'] = 2\n",
        "\n",
        "# MinMax normalization (from 0 to 1)\n",
        "train_df['vibration_norm'] = train_df['vibration']\n",
        "cols_normalize = train_df.columns.difference(['ID','revolutions','humidity','vibration','RUL','label1','label2'])\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "norm_train_df = pd.DataFrame(min_max_scaler.fit_transform(train_df[cols_normalize]),\n",
        "                             columns=cols_normalize,\n",
        "                             index=train_df.index)\n",
        "join_df = train_df[train_df.columns.difference(cols_normalize)].join(norm_train_df)\n",
        "train_df = join_df.reindex(columns = train_df.columns)\n",
        "\n",
        "######\n",
        "# TEST\n",
        "######\n",
        "# MinMax normalization (from 0 to 1)\n",
        "test_df['vibration_norm'] = test_df['vibration']\n",
        "norm_test_df = pd.DataFrame(min_max_scaler.transform(test_df[cols_normalize]),\n",
        "                            columns=cols_normalize,\n",
        "                            index=test_df.index)\n",
        "test_join_df = test_df[test_df.columns.difference(cols_normalize)].join(norm_test_df)\n",
        "test_df = test_join_df.reindex(columns = test_df.columns)\n",
        "test_df = test_df.reset_index(drop=True)\n",
        "test_df.head()\n",
        "\n",
        "# Generate column max for test data\n",
        "rul = pd.DataFrame(test_df.groupby('ID')['vibration'].max()).reset_index()\n",
        "rul.columns = ['ID', 'max']\n",
        "\n",
        "# Merge 'rul' with 'test_df'\n",
        "test_df = test_df.merge(rul, on='ID', how='left')\n",
        "\n",
        "# Calculate the RUL\n",
        "test_df['RUL'] = test_df['max'] - test_df['vibration']\n",
        "test_df.drop('max', axis=1, inplace=True)\n",
        "\n",
        "# Generate label columns w0 and w1 for test data\n",
        "test_df['label1'] = np.where(test_df['RUL'] <= w1, 1, 0)\n",
        "test_df['label2'] = test_df['label1']\n",
        "test_df.loc[test_df['RUL'] <= w0, 'label2'] = 2\n",
        "\n",
        "# Reset index if needed\n",
        "test_df = test_df.reset_index(drop=True)\n",
        "\n",
        "# Print the first few rows of the updated test_df\n",
        "print(test_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "812c7742",
      "metadata": {},
      "source": [
        " <span style=\"color:#0F3460;font-size:19px; font-weight: bold;\">1.10 Function to reshape dataset as required by LSTM</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03f11319",
      "metadata": {},
      "outputs": [],
      "source": [
        "def gen_sequence(id_df, seq_length, seq_cols):\n",
        "    data_array = id_df[seq_cols].values\n",
        "    num_elements = data_array.shape[0]\n",
        "    if num_elements < seq_length:\n",
        "        return []  # Not enough data to generate sequences\n",
        "    sequences = [data_array[start:start + seq_length, :] for start in range(num_elements - seq_length + 1)]\n",
        "    return sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd89dcd9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define sequence length and columns to use\n",
        "feature_columns = ['revolutions', 'humidity', 'vibration']\n",
        "sequence_length = 1\n",
        "\n",
        "# Filter IDs with enough data\n",
        "valid_ids = [id for id in train_df['ID'].unique() if len(train_df[train_df['ID'] == id]) >= sequence_length]\n",
        "\n",
        "# Generator for the sequences\n",
        "seq_gen = (gen_sequence(train_df[train_df['ID'] == id], sequence_length, feature_columns) for id in valid_ids)\n",
        "\n",
        "# Generate sequences and convert to numpy array\n",
        "all_sequences = []\n",
        "for sequences in seq_gen:\n",
        "    all_sequences.extend(sequences)\n",
        "\n",
        "seq_array = np.array(all_sequences, dtype=np.float32)\n",
        "seq_array.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8242bafc",
      "metadata": {},
      "outputs": [],
      "source": [
        "def gen_labels(id_df, seq_length, label_col):\n",
        "    data_array = id_df[label_col].values\n",
        "    num_elements = len(data_array)\n",
        "    labels = [data_array[start + seq_length - 1] for start in range(num_elements - seq_length + 1)]\n",
        "    return labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f2def92",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generator for labels\n",
        "label_gen = (gen_labels(train_df[train_df['ID'] == id], sequence_length, ['label1']) for id in valid_ids)\n",
        "\n",
        "all_labels = []\n",
        "for labels in label_gen:\n",
        "    all_labels.extend(labels)\n",
        "\n",
        "label_array = np.array(all_labels, dtype=np.float32)\n",
        "label_array.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de1ebdc3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for NaNs or infinities in the data\n",
        "print(np.any(np.isnan(seq_array)), np.any(np.isinf(seq_array)))\n",
        "print(np.any(np.isnan(label_array)), np.any(np.isinf(label_array)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69e2659a",
      "metadata": {},
      "outputs": [],
      "source": [
        "nan_indices = np.isnan(seq_array)\n",
        "print(np.where(nan_indices))  # Output indices where NaNs are present\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "884184e6",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Create an imputer\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "\n",
        "# Impute the 'vibration' column\n",
        "df_seq['vibration'] = imputer.fit_transform(df_seq[['vibration']])\n",
        "\n",
        "# Convert back to numpy array\n",
        "seq_array_imputed = df_seq.values.reshape(-1, sequence_length, nb_features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afa5c703",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(np.any(np.isnan(seq_array_clean)), np.any(np.isinf(seq_array_clean)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc841266",
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Example dummy data for seq_array and label_array\n",
        "# Replace these with your actual data\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Feature weights\n",
        "nb_features = seq_array.shape[2]\n",
        "nb_out = label_array.shape[1]\n",
        "\n",
        "model = Sequential()  # Define the model\n",
        "\n",
        "# First LSTM layer\n",
        "model.add(LSTM(\n",
        "    input_shape=(sequence_length, nb_features),\n",
        "    units=128,  # Set input shape for the first layer\n",
        "    return_sequences=True  # Set to True because we have a second LSTM layer\n",
        "))\n",
        "# Plus a 30% dropout rate\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Second LSTM layer\n",
        "model.add(LSTM(\n",
        "    units=64,  # Adjust the number of units as needed\n",
        "    return_sequences=False\n",
        "))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# # Third LSTM layer\n",
        "# model.add(LSTM(\n",
        "#     units=64,\n",
        "#     return_sequences=False\n",
        "# ))\n",
        "# model.add(Dropout(0.2))\n",
        "\n",
        "# Dense sigmoid layer\n",
        "model.add(Dense(units=nb_out, activation='sigmoid'))\n",
        "\n",
        "# With adam optimizer and a binary crossentropy loss. We will optimize for model accuracy.\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Verify the architecture\n",
        "print(model.summary())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af763ace",
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "#EarlyStopping callback\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta=0,         \n",
        "    patience=5,    \n",
        "    verbose=0,   \n",
        "    mode='auto'    \n",
        ")\n",
        "# Train the model\n",
        "history=model.fit(\n",
        "    seq_array, \n",
        "    label_array,\n",
        "    epochs=10,        \n",
        "    batch_size=200,\n",
        "    validation_split=0.10,  \n",
        "    verbose=1,          # Verbosity mode\n",
        "    callbacks=[early_stopping]  # Add early stopping callback\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2716b0a",
      "metadata": {},
      "source": [
        "<hr>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f17dae6a",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(pd.Series(label_array.flatten()).value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7893e06d",
      "metadata": {},
      "source": [
        "<span style=\"color:#0F3460;font-size:19px; font-weight: bold;\">Results</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21d7c401",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig_acc = plt.figure(figsize=(5, 5))\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21d7c401",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig_acc = plt.figure(figsize=(5, 5))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87745495",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, f1_score, roc_auc_score, roc_curve, precision_score, recall_score\n",
        "\n",
        "def print_results(y_test, y_pred):\n",
        "    # F1 Score\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    print(\"F1 Score: \", f1)\n",
        "\n",
        "    # Confusion Matrix\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    \n",
        "    plt.subplot(121)\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.ylabel('True Values')\n",
        "    plt.xlabel('Predicted Values')\n",
        "    \n",
        "    # ROC AUC Score\n",
        "    model_roc_auc = roc_auc_score(y_test, y_pred)\n",
        "    print(\"Area under curve: \", model_roc_auc, \"\\n\")\n",
        "    \n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "    gmeans = np.sqrt(tpr * (1 - fpr))\n",
        "    ix = np.argmax(gmeans)\n",
        "    best_threshold = np.round(thresholds[ix], 3)\n",
        "    \n",
        "    plt.subplot(122)\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='AUC: %.3f' % model_roc_auc)\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.scatter(fpr[ix], tpr[ix], marker='o', color='black', label='Best Threshold: ' + str(best_threshold))\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic')\n",
        "    plt.legend(loc='lower right')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e1f2998",
      "metadata": {},
      "outputs": [],
      "source": [
        "# training metrics\n",
        "scores = model.evaluate(seq_array, label_array, verbose=1, batch_size=128)\n",
        "print('Accurracy of model on training data: {}'.format(scores[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57200a58",
      "metadata": {},
      "outputs": [],
      "source": [
        "# make predictions and compute confusion matrix\n",
        "y_pred_prob = model.predict(seq_array, verbose=1, batch_size=128)\n",
        "\n",
        "# Convert probabilities to class labels\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "\n",
        "# Flatten the predictions to match the shape of y_test\n",
        "y_pred = y_pred.flatten()\n",
        "\n",
        "# Assuming y_true is the true labels\n",
        "y_true = label_array.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1eaabfdc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute and print precision and recall\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "print('Precision: ', precision)\n",
        "print('Recall: ', recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d413d1c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print results\n",
        "print_results(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18cad847",
      "metadata": {},
      "source": [
        " <span style=\"color:#0F3460;font-size:19px; font-weight: bold;\">Prediction</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e6bb6fc",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define thresholds for maintenance (example values, adjust based on your epm_clean)\n",
        "revolutions_threshold = 1000\n",
        "humidity_threshold = 75\n",
        "vibration_threshold = 50\n",
        "\n",
        "# Create the 'maintenance_needed' column based on the criteria\n",
        "epm_clean['maintenance_needed'] = ((epm_clean['revolutions'] > revolutions_threshold) |\n",
        "                              (epm_clean['humidity'] > humidity_threshold) |\n",
        "                              (epm_clean['vibration'] > vibration_threshold)).astype(int)\n",
        "\n",
        "# Check the new column\n",
        "print(epm_clean[['revolutions', 'humidity', 'vibration', 'maintenance_needed']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31238ba3",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Features and target variable\n",
        "X = epm_clean[['revolutions', 'humidity', 'vibration']]\n",
        "y = epm_clean['maintenance_needed']\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1 Score: {f1}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "216f8898",
      "metadata": {},
      "outputs": [],
      "source": [
        "# New data for prediction\n",
        "new_data = pd.DataFrame({\n",
        "    'revolutions': [800, 1200, 950, 1100],\n",
        "    'humidity': [60, 80, 70, 90],\n",
        "    'vibration': [40, 60, 45, 55]\n",
        "})\n",
        "\n",
        "# Predict maintenance needed\n",
        "predictions = model.predict(new_data)\n",
        "print(predictions)  # Output will be an array of 0s and 1s indicating maintenance needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb4f6cd7",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Example data\n",
        "data = pd.DataFrame({\n",
        "    'revolutions': [800, 850, 900, 950, 1000, 1050, 1100],\n",
        "    'humidity': [60, 62, 65, 68, 70, 73, 75],\n",
        "    'vibration': [40, 42, 44, 46, 48, 50, 52]\n",
        "})\n",
        "\n",
        "# Simulate a time index\n",
        "data['time'] = pd.date_range(start='2024-07-23', periods=len(data), freq='D')\n",
        "data.set_index('time', inplace=True)\n",
        "\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07e4453b",
      "metadata": {},
      "outputs": [],
      "source": [
        "epm_clean['revolutions_smooth'] = epm_clean['revolutions'].rolling(window=2).mean()\n",
        "epm_clean['humidity_smooth'] = epm_clean['humidity'].rolling(window=2).mean()\n",
        "epm_clean['vibration_smooth'] = epm_clean['vibration'].rolling(window=2).mean()\n",
        "\n",
        "print(epm_clean)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
